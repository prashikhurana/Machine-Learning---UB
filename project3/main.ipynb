{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPElny1lpYDe",
        "colab_type": "text"
      },
      "source": [
        "#**KMEANS WITH NORMALISED MUTUTAL INFO SCORE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p5Uam-0m8CE",
        "colab_type": "code",
        "outputId": "593e64f2-b01e-4f9e-af6a-4b4e19ebcd80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "print(\"Normal KMeans Clustering\")\n",
        "(x_train, y_train), (x_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X = x_train.reshape(len(x_train),-1)\n",
        "Y = y_train\n",
        "X = X.astype(float) / 255.\n",
        "\n",
        "x_test = x_test.reshape(len(x_test),-1)\n",
        "x_test = x_test.astype(float) / 255.\n",
        "\n",
        "n_digits = len(np.unique(y_test))\n",
        "kmeans = KMeans(n_clusters = n_digits)\n",
        "kmeans.fit(X)\n",
        "predicted_labels = kmeans.predict(x_test)\n",
        "cm = confusion_matrix(y_test, predicted_labels)\n",
        "print(\"Confusion Matrix\")\n",
        "print(cm)\n",
        "print('Accuracy: {}\\n'.format(metrics.normalized_mutual_info_score(y_test, predicted_labels)))\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(classification_report(y_test,predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Normal KMeans Clustering\n",
            "Confusion Matrix\n",
            "[[585  96 242  31   0   6  34   0   5   1]\n",
            " [ 50  22  28 891   0   0   9   0   0   0]\n",
            " [ 20  65 338   4   0   4 565   0   4   0]\n",
            " [277  99 105 504   0   2  10   0   3   0]\n",
            " [134  42 163  27   0   4 625   0   5   0]\n",
            " [  0 646   6   0  45   0   0  73   0 230]\n",
            " [189 121 355  12   0  15 308   0   0   0]\n",
            " [  0  59   0   0   2   0   0 152   0 787]\n",
            " [  3  87  30   7   1 355  60  10 408  39]\n",
            " [  0  29   4   0 423   0   0 519   2  23]]\n",
            "Accuracy: 0.5123862279056837\n",
            "\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.58      0.52      1000\n",
            "           1       0.02      0.02      0.02      1000\n",
            "           2       0.27      0.34      0.30      1000\n",
            "           3       0.34      0.50      0.41      1000\n",
            "           4       0.00      0.00      0.00      1000\n",
            "           5       0.00      0.00      0.00      1000\n",
            "           6       0.19      0.31      0.24      1000\n",
            "           7       0.20      0.15      0.17      1000\n",
            "           8       0.96      0.41      0.57      1000\n",
            "           9       0.02      0.02      0.02      1000\n",
            "\n",
            "    accuracy                           0.23     10000\n",
            "   macro avg       0.25      0.23      0.22     10000\n",
            "weighted avg       0.25      0.23      0.22     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkRjVvARmnv2",
        "colab_type": "text"
      },
      "source": [
        "# **KMEANS ACCURACY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUQr82GqloJg",
        "colab_type": "code",
        "outputId": "e90ac0bc-0c76-412b-ff91-8a04cff64c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "print(\"Normal KMeans Clustering\")\n",
        "(x_train, y_train), (x_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X = x_train.reshape(len(x_train),-1)\n",
        "Y = y_train\n",
        "X = X.astype(float) / 255.\n",
        "\n",
        "x_test = x_test.reshape(len(x_test),-1)\n",
        "x_test = x_test.astype(float) / 255.\n",
        "\n",
        "n_digits = len(np.unique(y_test))\n",
        "kmeans = KMeans(n_clusters = n_digits)\n",
        "kmeans.fit(X)\n",
        "\n",
        "def infer_cluster_labels(kmeans, actual_labels):\n",
        "    \"\"\"\n",
        "    Associates most probable label with each cluster in KMeans model\n",
        "    returns: dictionary of clusters assigned to each label\n",
        "    \"\"\"\n",
        "\n",
        "    inferred_labels = {}\n",
        "\n",
        "    for i in range(kmeans.n_clusters):\n",
        "\n",
        "        # find index of points in cluster\n",
        "        labels = []\n",
        "        index = np.where(kmeans.labels_ == i)\n",
        "\n",
        "        # append actual labels for each point in cluster\n",
        "        labels.append(actual_labels[index])\n",
        "\n",
        "        # determine most common label\n",
        "        if len(labels[0]) == 1:\n",
        "            counts = np.bincount(labels[0])\n",
        "        else:\n",
        "            counts = np.bincount(np.squeeze(labels))\n",
        "\n",
        "        # assign the cluster to a value in the inferred_labels dictionary\n",
        "        if np.argmax(counts) in inferred_labels:\n",
        "            # append the new number to the existing array at this slot\n",
        "            inferred_labels[np.argmax(counts)].append(i)\n",
        "        else:\n",
        "            # create a new array in this slot\n",
        "            inferred_labels[np.argmax(counts)] = [i]\n",
        "\n",
        "        #print(labels)\n",
        "        #print('Cluster: {}, label: {}'.format(i, np.argmax(counts)))\n",
        "        \n",
        "    return inferred_labels  \n",
        "\n",
        "def infer_data_labels(X_labels, cluster_labels):\n",
        "    \"\"\"\n",
        "    Determines label for each array, depending on the cluster it has been assigned to.\n",
        "    returns: predicted labels for each array\n",
        "    \"\"\"\n",
        "    \n",
        "    # empty array of len(X)\n",
        "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)\n",
        "    \n",
        "    for i, cluster in enumerate(X_labels):\n",
        "        for key, value in cluster_labels.items():\n",
        "            if cluster in value:\n",
        "                predicted_labels[i] = key\n",
        "                \n",
        "    return predicted_labels\n",
        "\n",
        "cluster_labels = infer_cluster_labels(kmeans, Y)\n",
        "X_clusters = kmeans.predict(x_test)\n",
        "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
        "cm = confusion_matrix(y_test, predicted_labels)\n",
        "print(\"CM\",cm)\n",
        "print('Accuracy: {}\\n'.format(metrics.accuracy_score(y_test, predicted_labels)))\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(classification_report(y_test,predicted_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal KMeans Clustering\n",
            "CM [[587  29   0   0  34  94 244   1  11   0]\n",
            " [ 50 890   0   0   9  22  29   0   0   0]\n",
            " [ 19   4   0   0 566  61 342   0   8   0]\n",
            " [277 503   0   0  10  93 112   0   5   0]\n",
            " [136  27   0   0 627  42 159   0   9   0]\n",
            " [  0   0   0   0   0 650   6 227   0 117]\n",
            " [189  12   0   0 311 115 358   0  15   0]\n",
            " [  0   0   0   0   0  62   0 785   0 153]\n",
            " [  3   6   0   0  61  84  35  40 761  10]\n",
            " [  0   0   0   0   0  29   4  23   2 942]]\n",
            "Accuracy: 0.56\n",
            "\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.59      0.52      1000\n",
            "           1       0.61      0.89      0.72      1000\n",
            "           2       0.00      0.00      0.00      1000\n",
            "           3       0.00      0.00      0.00      1000\n",
            "           4       0.39      0.63      0.48      1000\n",
            "           5       0.52      0.65      0.58      1000\n",
            "           6       0.28      0.36      0.31      1000\n",
            "           7       0.73      0.79      0.76      1000\n",
            "           8       0.94      0.76      0.84      1000\n",
            "           9       0.77      0.94      0.85      1000\n",
            "\n",
            "    accuracy                           0.56     10000\n",
            "   macro avg       0.47      0.56      0.51     10000\n",
            "weighted avg       0.47      0.56      0.51     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SkuF8KLpGGb",
        "colab_type": "text"
      },
      "source": [
        "# **AUTO ENCODER WITH KMEANS NORMALISED MUTUTAL INFO SCORE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iSKGqKNxdRE",
        "colab_type": "code",
        "outputId": "49f7fc99-a8eb-4304-bcea-e6636eb9185c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, UpSampling2D, Activation\n",
        "from keras import backend as K\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as metrics\n",
        "from keras import regularizers\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "print(\"KMeans Clustering with AutoEncoder\")\n",
        "\n",
        "(x_train, y_train), (x_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "#print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "x_train = x_train.astype('float32')/255.\n",
        "x_test = x_test.astype('float32')/255.\n",
        "\n",
        "x_train = x_train.reshape((len(x_train),np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test),np.prod(x_test.shape[1:])))\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "\n",
        "encoding_dim = 32\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(encoding_dim,activation='selu',kernel_regularizer=regularizers.l2(0.01))(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "autoencoder = Model(input_img,decoded)\n",
        "encoder = Model(input_img,encoded)\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "autoencoder.fit(x_train,x_train, epochs=60, batch_size=2056, shuffle=True, validation_data=(x_test,x_test))\n",
        "autoencoder.summary()\n",
        "encoded_images = encoder.predict(x_test)\n",
        "print(\"EncodedImagesSHape\", encoded_images.shape) \n",
        "\n",
        "kmeans = KMeans(n_clusters=10)\n",
        "kmeans.fit(encoded_images)\n",
        "predicted_labels = kmeans.predict(encoded_images)\n",
        "\n",
        "cm = confusion_matrix(y_test, predicted_labels)\n",
        "print(\"Confusion Matrix is\\n\",cm)\n",
        "print('Accuracy: {}\\n'.format(metrics.normalized_mutual_info_score(y_test, predicted_labels)))\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(classification_report(y_test,predicted_labels))\n",
        "\n",
        "history = autoencoder.fit(x_train, x_train, epochs=4, batch_size=64, verbose=1)\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()\n",
        "\n",
        "history = autoencoder.fit(x_test, x_test, epochs=4, batch_size=64, verbose=1)\n",
        "\n",
        "# summarize history for test\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans Clustering with AutoEncoder\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 8us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 5s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 0us/step\n",
            "(60000, 784)\n",
            "(10000, 784)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3492: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/60\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 1.0080 - val_loss: 0.7387\n",
            "Epoch 2/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.6244 - val_loss: 0.5369\n",
            "Epoch 3/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.4973 - val_loss: 0.4664\n",
            "Epoch 4/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.4503 - val_loss: 0.4381\n",
            "Epoch 5/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.4296 - val_loss: 0.4235\n",
            "Epoch 6/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.4176 - val_loss: 0.4137\n",
            "Epoch 7/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.4087 - val_loss: 0.4057\n",
            "Epoch 8/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.4012 - val_loss: 0.3988\n",
            "Epoch 9/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3946 - val_loss: 0.3927\n",
            "Epoch 10/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3889 - val_loss: 0.3875\n",
            "Epoch 11/60\n",
            "60000/60000 [==============================] - 0s 7us/step - loss: 0.3839 - val_loss: 0.3829\n",
            "Epoch 12/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3795 - val_loss: 0.3788\n",
            "Epoch 13/60\n",
            "60000/60000 [==============================] - 0s 7us/step - loss: 0.3755 - val_loss: 0.3750\n",
            "Epoch 14/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3718 - val_loss: 0.3714\n",
            "Epoch 15/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3683 - val_loss: 0.3682\n",
            "Epoch 16/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3653 - val_loss: 0.3654\n",
            "Epoch 17/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3624 - val_loss: 0.3627\n",
            "Epoch 18/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3598 - val_loss: 0.3603\n",
            "Epoch 19/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3574 - val_loss: 0.3579\n",
            "Epoch 20/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3553 - val_loss: 0.3559\n",
            "Epoch 21/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3534 - val_loss: 0.3542\n",
            "Epoch 22/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3517 - val_loss: 0.3525\n",
            "Epoch 23/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3501 - val_loss: 0.3511\n",
            "Epoch 24/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3487 - val_loss: 0.3497\n",
            "Epoch 25/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3474 - val_loss: 0.3486\n",
            "Epoch 26/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3462 - val_loss: 0.3474\n",
            "Epoch 27/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3451 - val_loss: 0.3462\n",
            "Epoch 28/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3441 - val_loss: 0.3453\n",
            "Epoch 29/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3431 - val_loss: 0.3444\n",
            "Epoch 30/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3422 - val_loss: 0.3438\n",
            "Epoch 31/60\n",
            "60000/60000 [==============================] - 0s 7us/step - loss: 0.3415 - val_loss: 0.3427\n",
            "Epoch 32/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3405 - val_loss: 0.3420\n",
            "Epoch 33/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3398 - val_loss: 0.3412\n",
            "Epoch 34/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3390 - val_loss: 0.3405\n",
            "Epoch 35/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3383 - val_loss: 0.3400\n",
            "Epoch 36/60\n",
            "60000/60000 [==============================] - 0s 7us/step - loss: 0.3377 - val_loss: 0.3391\n",
            "Epoch 37/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3369 - val_loss: 0.3384\n",
            "Epoch 38/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3363 - val_loss: 0.3378\n",
            "Epoch 39/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3358 - val_loss: 0.3376\n",
            "Epoch 40/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3351 - val_loss: 0.3368\n",
            "Epoch 41/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3346 - val_loss: 0.3361\n",
            "Epoch 42/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3339 - val_loss: 0.3357\n",
            "Epoch 43/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3334 - val_loss: 0.3351\n",
            "Epoch 44/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3329 - val_loss: 0.3344\n",
            "Epoch 45/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3323 - val_loss: 0.3338\n",
            "Epoch 46/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3319 - val_loss: 0.3334\n",
            "Epoch 47/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3314 - val_loss: 0.3328\n",
            "Epoch 48/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3307 - val_loss: 0.3323\n",
            "Epoch 49/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3303 - val_loss: 0.3320\n",
            "Epoch 50/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3298 - val_loss: 0.3317\n",
            "Epoch 51/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3293 - val_loss: 0.3310\n",
            "Epoch 52/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3289 - val_loss: 0.3311\n",
            "Epoch 53/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3285 - val_loss: 0.3301\n",
            "Epoch 54/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3280 - val_loss: 0.3296\n",
            "Epoch 55/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3275 - val_loss: 0.3293\n",
            "Epoch 56/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3271 - val_loss: 0.3290\n",
            "Epoch 57/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3268 - val_loss: 0.3285\n",
            "Epoch 58/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3264 - val_loss: 0.3280\n",
            "Epoch 59/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3263 - val_loss: 0.3283\n",
            "Epoch 60/60\n",
            "60000/60000 [==============================] - 0s 6us/step - loss: 0.3257 - val_loss: 0.3274\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 784)               25872     \n",
            "=================================================================\n",
            "Total params: 50,992\n",
            "Trainable params: 50,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "EncodedImagesSHape (10000, 32)\n",
            "Confusion Matrix is\n",
            " [[ 45   2 256   0   0   4  28   7   6 652]\n",
            " [  4   0  34   0   0   0 901  10   1  50]\n",
            " [301   0 303   0   0   4   4 368   6  14]\n",
            " [  3   0 185   0   0   2 536  16   1 257]\n",
            " [146   0 135   0   0   5  28 589   2  95]\n",
            " [  0 565 111 159 163   0   0   0   2   0]\n",
            " [143   3 365   0   0   2  13 247  12 215]\n",
            " [  0 837   0   2 160   0   0   0   1   0]\n",
            " [ 66  46 106   0   7 386   4   6 374   5]\n",
            " [  0  25   8 402 561   0   0   1   1   2]]\n",
            "Accuracy: 0.5203407930096117\n",
            "\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.06      0.04      0.05      1000\n",
            "           1       0.00      0.00      0.00      1000\n",
            "           2       0.20      0.30      0.24      1000\n",
            "           3       0.00      0.00      0.00      1000\n",
            "           4       0.00      0.00      0.00      1000\n",
            "           5       0.00      0.00      0.00      1000\n",
            "           6       0.01      0.01      0.01      1000\n",
            "           7       0.00      0.00      0.00      1000\n",
            "           8       0.92      0.37      0.53      1000\n",
            "           9       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.07     10000\n",
            "   macro avg       0.12      0.07      0.08     10000\n",
            "weighted avg       0.12      0.07      0.08     10000\n",
            "\n",
            "Epoch 1/4\n",
            " 1664/60000 [..............................] - ETA: 4s - loss: 0.3280"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3230\n",
            "Epoch 2/4\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.3177\n",
            "Epoch 3/4\n",
            "60000/60000 [==============================] - 5s 75us/step - loss: 0.3140\n",
            "Epoch 4/4\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.3113\n",
            "dict_keys(['loss'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3hVZbr+8e+TDoRepEqoKkUpAaQI\nFvBYRhErWFBUEJTjMDpzZObnnDk6veBgQRAUOyKKOqjD6AiKQAQJiCCIAqHXgEDokPD8/shi3CIl\nCdlZKffnuvY1e7+r5HndTO6s9a71LnN3RERE8iom7AJERKRkUXCIiEi+KDhERCRfFBwiIpIvCg4R\nEckXBYeIiOSLgkMkSswsxczczOLysO4dZjbrdPcjUhQUHCKAma02s0NmVuOY9i+CX9op4VQmUvwo\nOES+twrod/SDmbUGyodXjkjxpOAQ+d7LQP+Iz7cDL0WuYGaVzewlM8s0szVm9rCZxQTLYs3sb2a2\nzcwygCuPs+1zZrbJzDaY2e/MLDa/RZpZXTObYmbfmdkKMxsYsayjmaWbWZaZbTGzx4L2JDN7xcy2\nm9lOM5tnZmfk92eLgIJDJNIcoJKZnRP8Qu8LvHLMOk8ClYHGQA9yg2ZAsGwg8BOgLZAKXH/Mti8A\n2UDTYJ1LgbsLUOdEYD1QN/gZfzCzi4NljwOPu3sloAkwKWi/Pai7AVAdGAzsL8DPFlFwiBzj6FFH\nL+BrYMPRBRFh8kt33+3uq4ERwG3BKjcCI919nbt/B/wxYtszgCuAYe6+1923An8P9pdnZtYA6Ao8\n5O4H3H0h8CzfHykdBpqaWQ133+PucyLaqwNN3T3H3ee7e1Z+frbIUQoOkR96GbgZuINjTlMBNYB4\nYE1E2xqgXvC+LrDumGVHNQy23RScKtoJPAPUymd9dYHv3H33CWq4C2gOLAtOR/0kol8fABPNbKOZ\n/cXM4vP5s0UABYfID7j7GnIHya8A3jpm8TZy/3JvGNF2Jt8flWwi91RQ5LKj1gEHgRruXiV4VXL3\nlvkscSNQzcwqHq8Gd1/u7v3IDaQ/A2+aWQV3P+zuj7h7C6ALuafU+iNSAAoOkR+7C7jY3fdGNrp7\nDrljBr83s4pm1hB4gO/HQSYB95tZfTOrCgyP2HYT8CEwwswqmVmMmTUxsx75Kczd1wFpwB+DAe9z\ng3pfATCzW82sprsfAXYGmx0xs4vMrHVwui2L3AA8kp+fLXKUgkPkGO6+0t3TT7D4v4G9QAYwC5gA\njA+WjSP3dNCXwAJ+fMTSH0gAlgI7gDeBOgUosR+QQu7Rx9vAb9z9o2DZZcASM9tD7kB5X3ffD9QO\nfl4WuWM3M8g9fSWSb6YHOYmISH7oiENERPJFwSEiIvmi4BARkXxRcIiISL6UiWmaa9So4SkpKWGX\nISJSosyfP3+bu9c8tr1MBEdKSgrp6Se6ulJERI7HzNYcr12nqkREJF8UHCIiki8KDhERyRcFh4iI\n5IuCQ0RE8kXBISIi+aLgEBGRfFFwnMQrc9Ywc3lm2GWIiBQrCo4TOJR9hFfnrmXA8/OYPH992OWI\niBQbCo4TSIiL4fV7zqdDSjUefONLRn28Aj27REREwXFSlZLiefHOjvRuU5e/fvAND7/zFdk5etqm\niJRtZWKuqtOREBfD329sQ53K5RgzYyVbsg7wZL92lEuIDbs0EZFQ6IgjD2JijOGXn82jvVsybdlW\n+o2bw/Y9B8MuS0QkFAqOfOjfOYXRt7Tn601ZXDc6jTXb94ZdkohIkVNw5NNlrWozYWAndu4/zLVP\np7Fw3c6wSxIRKVIKjgJo37Aak4d0oXxiLP3GzmHa11vCLklEpMgoOAqoSc1kJg/pQtNayQx8KZ3X\nPl8bdkkiIkVCwXEaalVMYuKg87mgWU1++dZiHvvwG93rISKlnoLjNFVIjOPZ21O5MbU+T0xfwc/f\nWMRh3eshIqWY7uMoBPGxMfz5unOpW6UcIz9aztbdBxh9a3uSE/WfV0RKHx1xFBIzY1jP5vz5utak\nrdzOTc98xtasA2GXJSJS6BQcheymDmfybP9UMjL30ufpNFZs3RN2SSIihSqqwWFml5nZN2a2wsyG\nH2f5YDNbbGYLzWyWmbUI2nuZ2fxg2XwzuzhoL29m75vZMjNbYmZ/imb9BXXR2bV4/Z7zOZidw/Vj\n0khf/V3YJYmIFJqoBYeZxQKjgMuBFkC/o8EQYYK7t3b3NsBfgMeC9m3AVe7eGrgdeDlim7+5+9lA\nW6CrmV0erT6cjnPrV+GtIV2pWj6Bm5+dy9TFm8IuSUSkUETziKMjsMLdM9z9EDAR6B25grtnRXys\nAHjQ/oW7bwzalwDlzCzR3fe5+8fBOoeABUD9KPbhtJxZvTyTh3ShVd1K3DthAc/PXhV2SSIipy2a\nwVEPWBfxeX3Q9gNmdp+ZrST3iOP+4+znOmCBux88ZrsqwFXAtOP9cDMbZGbpZpaemRneU/yqVUjg\n1bvPp9c5Z/DIu0v5wz+/5sgR3eshIiVX6IPj7j7K3ZsADwEPRy4zs5bAn4F7jmmPA14DnnD3jBPs\nd6y7p7p7as2aNaNTfB6VS4hl9K3tue38hoz9NIOfvr6Qg9k5odYkIlJQ0bzRYAPQIOJz/aDtRCYC\no49+MLP6wNtAf3dfecy6Y4Hl7j6ykGqNutgY49HeLalbpRx//tcyMncf4JnbUqlcLj7s0kRE8iWa\nRxzzgGZm1sjMEoC+wJTIFcysWcTHK4HlQXsV4H1guLvPPmab3wGVgWFRrD0qzIwhFzbh7zedx/w1\nO7hxzGds3Lk/7LJERPIlasHh7tnAUOAD4GtgkrsvMbNHzezqYLWhwWW1C4EHyL2CimC7psD/Bpfq\nLjSzWsFRyP8j9yqtBUH73dHqQ7T0aVufFwZ0ZOPO/Vz7dBrLNmedeiMRkWLCysKkfKmpqZ6enh52\nGT/y9aYs7nj+c/YdzOGZ29rTpWmNsEsSEfkPM5vv7qnHtoc+OF6WnVOnEm/d25XalZO4/fnP+cfC\nkw0BiYgUDwqOkNWrUo43B3eh3ZlV+enEhYyZsVJTs4tIsabgKAYql4/npbs68pNz6/Cnqcv4vylL\nyNG9HiJSTGne72IiMS6WJ/q2pU7lJMbNXMXmrAM83rctSfGxYZcmIvIDOuIoRmJijP93ZQv+9yct\n+HDpFm4eN4cdew+FXZaIyA8oOIqhO7s1YtTN7fhqYxbXjU5j3Xf7wi5JROQ/FBzF1BWt6/DKXZ3Y\nvvcQfZ5OY/H6XWGXJCICKDiKtY6NqjF5SGcS42K4aexnfPzN1rBLEhFRcBR3TWtV5O17u5BSvQJ3\nv5jOpHnrTr2RiEgUKThKgFqVknj9nvPp0qQ6/zN5ESM/+lb3eohIaBQcJUTFpHjG39GBa9vVY+RH\ny/nlW4vJzjkSdlkiUgbpPo4SJD42hhE3nEe9KuV4cvoKtmQd4Kmb21EhUV+jiBQdHXGUMGbGg5ee\nxe/7tGLGt5n0GzeHzN0HT72hiEghUXCUULd0asjY21L5dsturh09m4zMPWGXJCJlhIKjBOvZ4gwm\nDurM3oM5XDc6jflrdoRdkoiUAQqOEq5Ngyq8NaQLlcrFc/O4OXy4ZHPYJYlIKafgKAVSalRg8pAu\nnF2nEoNfmc/Lc9aEXZKIlGIKjlKiRnIirw3sxEVn1eLX73zFn/+1TPd6iEhUKDhKkfIJcTxzW3tu\n7nQmoz9ZyQOTvuRQtu71EJHCpRsASpm42Bh+f00r6lZO4m8ffsvW3QcYfWt7KiXFh12aiJQSOuIo\nhcyMoRc34283nMfcjO+4ccxnbN51IOyyRKSUUHCUYte3r8/4Ozqw7rt9XPv0bL7dsjvskkSkFFBw\nlHLdm9dk0uDOHD7iXD86jTkZ28MuSURKOAVHGdCybmXevrcLNSsm0v+5z3lv0cawSxKREkzBUUbU\nr1qeyUO6cF6Dygyd8AXPzswIuyQRKaGiGhxmdpmZfWNmK8xs+HGWDzazxWa20MxmmVmLoL2Xmc0P\nls03s4sjtmkftK8wsyfMzKLZh9KkSvkEXr6rE5e3qs3v3v+aR99dypEjutdDRPInasFhZrHAKOBy\noAXQ72gwRJjg7q3dvQ3wF+CxoH0bcJW7twZuB16O2GY0MBBoFrwui1YfSqOk+FhG3dyOAV1TGD97\nFUNfW8CBwzlhlyUiJUg0jzg6AivcPcPdDwETgd6RK7h7VsTHCoAH7V+4+9ET8UuAcmaWaGZ1gEru\nPsdzb4t+Cbgmin0olWJijN9c1ZKHrzyHfy7eTP/nPmfnvkNhlyUiJUQ0g6MeEPmA7PVB2w+Y2X1m\ntpLcI477j7Of64AF7n4w2H79qfYZ7HeQmaWbWXpmZmYBu1C63X1BY57s15aF63Zy/ZjPWL9jX9gl\niUgJEPrguLuPcvcmwEPAw5HLzKwl8GfgngLsd6y7p7p7as2aNQun2FLoqvPq8uKdHdmSdYA+T6ex\nZOOusEsSkWIumsGxAWgQ8bl+0HYiE4k47WRm9YG3gf7uvjJin/XzsU/Jg85NqjN5SBfiY4wbx3zG\nzOU6QhORE4tmcMwDmplZIzNLAPoCUyJXMLNmER+vBJYH7VWA94Hh7j776AruvgnIMrPzg6up+gP/\niGIfyozmZ1TkrXu70qBaeQY8P4/J89efeiMRKZOiFhzung0MBT4AvgYmufsSM3vUzK4OVhtqZkvM\nbCHwALlXUBFs1xT43+BS3YVmVitYdi/wLLACWAlMjVYfypralZOYNLgznRpX48E3vmTUxys0NbuI\n/IiVhV8Mqampnp6eHnYZJcah7CP8z5tf8s7CjdzS6UweubolcbGhD4eJSBEzs/nunnpsu6ZVlx9J\niIvhsRvbUKdKOUZ/spItWQd4ol9byifon4uIFIOrqqR4iokxHrrsbH7buyXTl22l37i5bN9zMOyy\nRKQYUHDISd3WOYUxt7Zn2aYsrhudxprte8MuSURCpuCQU7q0ZW0mDDyfXfsPc+3TaSxctzPskkQk\nRAoOyZP2DasyeUgXyifG0m/sHKZ9vSXskkQkJAoOybPGNZN5a0hXmtZKZuBL6UyYuzbskkQkBAoO\nyZeaFROZOOh8ejSvya/eXsyID7/RvR4iZYyCQ/KtQmIc4/qnclNqA56cvoKfv7GIwzlHwi5LRIqI\nLsyXAomLjeFP17WmTpUkRn60nK27DzD61vYkJ+qflEhppyMOKTAzY1jP5vzlunNJW7mdm575jK1Z\nB8IuS0SiTMEhp+3GDg149vZUVm3bS5+n01ixdXfYJYlIFCk4pFBcdFYtXh/UmYPZR7hu9GfMW/1d\n2CWJSJQoOKTQtK5fmbfv7UL1Cgnc8uxcpi7eFHZJIhIFCg4pVA2qlefNIV1oVbcS905YwPOzV4Vd\nkogUMgWHFLpqFRKYMPB8ep1zBo+8u5Q//PNrjhzRvR4ipYWCQ6IiKT6W0be2p3/nhoz9NIOfvr6Q\ng9k5YZclIoVAF91L1MTGGI9c3ZK6Vcrxp6nL2Jp1gLH9U6lcLj7s0kTkNOiIQ6LKzBjcowmP923D\ngrU7uGFMGht37g+7LBE5DQoOKRK929TjxQEd2bTzANc+ncayzVlhlyQiBaTgkCLTpWkNJg3uDMAN\noz8jbcW2kCsSkYJQcEiROqdOJd66twt1qiRx+/Of84+FG8IuSUTyScEhRa5ulXK8MbgL7RtW5acT\nFzL6k5Waml2kBFFwSCgql4vnxTs7ctV5dfnzv5bxmylLyNG9HiIlgi7HldAkxsXy+E1tqFM5ibGf\nZrAl6wCP921LUnxs2KWJyEnoiENCFRNj/OqKc/jNVS34cOkWbh43hx17D4VdloicRFSDw8wuM7Nv\nzGyFmQ0/zvLBZrbYzBaa2SwzaxG0Vzezj81sj5k9dcw2/YJtFpnZv8ysRjT7IEVjQNdGPH1zO77a\nmMV1o9NY992+sEsSkROIWnCYWSwwCrgcaAH0OxoMESa4e2t3bwP8BXgsaD8A/Br4+TH7jAMeBy5y\n93OBRcDQaPVBitblresw4e5ObN97iD5Pz2bx+l1hlyQixxHNI46OwAp3z3D3Q8BEoHfkCu4eeRdY\nBcCD9r3uPovcAIlkwauCmRlQCdgYpfolBKkp1Zg8pAuJcbHcNPYzPv5ma9glicgxohkc9YB1EZ/X\nB20/YGb3mdlKco847j/ZDt39MDAEWExuYLQAnjveumY2yMzSzSw9MzOzYD2QUDStlczb93ahUY0K\n3P1iOpPmrTv1RiJSZEIfHHf3Ue7eBHgIePhk65pZPLnB0RaoS+6pql+eYL9j3T3V3VNr1qxZyFVL\ntNWqlMTr93Sma9Ma/M/kRYz86Fvd6yFSTEQzODYADSI+1w/aTmQicM0p9tkGwN1Xeu5vkUlAl9Mp\nUoqv5MQ4nrs9levb12fkR8sZPnkxh3OOhF2WSJkXzeCYBzQzs0ZmlgD0BaZErmBmzSI+XgksP8U+\nNwAtzOzoIUQv4OtCqleKofjYGP56/bncf3FTXk9fx8CX0tl7MDvsskTKtKjdAOju2WY2FPgAiAXG\nu/sSM3sUSHf3KcBQM+sJHAZ2ALcf3d7MVpM7+J1gZtcAl7r7UjN7BPjUzA4Da4A7otUHKR7MjAcu\nPYvalcvx8DuLuWnsZ/z9xjY0O6Ni2KWJlElWFs4bp6amenp6ethlSCGYvmwLP3v9S/YezObuCxpz\n/yVNKZ+gCRBEosHM5rt76rHteTpVZWZNzCwxeH+hmd1vZlUKu0iRU7n47DOY/mAP+rStx5gZK+n1\n2Kd8sGSzBs5FilBexzgmAzlm1hQYS+6g94SoVSVyEtWTE/nrDefxxuDOJCfGcc/L87nrxXTWbtfd\n5iJFIa/BccTds4E+wJPu/gugTvTKEjm1DinVeO/+bjx85TnMzdhOr7/P4MlpyzmYnRN2aSKlWl6D\n47CZ9SN38Pq9oC0+OiWJ5F18bAx3X9CYjx7swSXn1GLEv7/l8pEzmbVcTxcUiZa8BscAoDPwe3df\nZWaNgJejV5ZI/tSpXI6nb2nPCwM6kOPOrc/NZeiEBWzJOnbWGhE5Xfm+qsrMqgIN3H1RdEoqfLqq\nqmw5cDiHMTNW8vQnK0mIjeGBXs3p37khcbGhT5QgUqKc7lVVn5hZJTOrBiwAxpnZY6faTiQMSfGx\nDOvZnA+Hdaddw6o8+t5SrnpqNvPX7Ai7NJFSIa9/glUOZrK9FnjJ3TsBPaNXlsjpS6lRgRcHdGD0\nLe3YsfcQ141OY/jkRXpQlMhpymtwxJlZHeBGvh8cFyn2zIzLW9fhowd7MKh7Y96Yv56LR3zC6/PW\nckTPOBcpkLwGx6PkTh2y0t3nmVljTj2vlEixkZwYx6+uOIf37+9G01rJPDR5MdePSWPpxqxTbywi\nP6ApR6TMcXfenL+eP05dxq79h7mjSwo/69Wc5ERNXSIS6XQHx+ub2dtmtjV4TTaz+oVfpkj0mRk3\npDZg+oM9uKlDA8bPXsUlIz7hvUUbNXWJSB7k9VTV8+ROiV43eL0btImUWFXKJ/CHPq15a0gXaiQn\nMnTCF/Qf/zkZmXvCLk2kWMtrcNR09+fdPTt4vQDosXpSKrQ9sypThnbjkatbsnDtTi4bOZPHPvyG\nA4c1dYnI8eQ1OLab2a1mFhu8bgW2R7MwkaIUG2Pc3iWFaT/vwRWta/PE9BX0+vsMPl62NezSRIqd\nvAbHneReirsZ2ARcjx6gJKVQrYpJjOzblgkDO5EQG8OAF+Zxz8vpbNi5P+zSRIqNAl9VZWbD3H1k\nIdcTFbqqSgriUPYRxs3M4MnpyzGMYT2bcWe3RsRr6hIpI07rqqoTeOA0thUp9hLiYrjvoqb8+2c9\n6Nq0Bn+cuowrn5jJ3AydpZWy7XSCwwqtCpFirEG18jx7eyrj+qey92AON42dwwOTFrJtz8GwSxMJ\nxekEhy54lzKlV4sz+OiBHtx3URPe/XIjF//tE16es4YcTV0iZcxJg8PMdptZ1nFeu8m9n0OkTCmX\nEMsv/utspv60O63qVebX73xFn6dns2j9zrBLEykyJw0Od6/o7pWO86ro7pqfQcqsprWSefXuTjze\ntw2bdh2g96jZ/Pqdr9i1/3DYpYlEnS4PESkgM6N3m3pMe7AHt3dO4dW5a7hkxCe8tWC9pi6RUk3B\nIXKaKiXF839Xt2TK0G7Uq1qeByZ9Sd+xc1i+ZXfYpYlEhYJDpJC0qleZt4d04Q99WrNs824uf3wm\nf5q6jH2HssMuTaRQRTU4zOwyM/vGzFaY2fDjLB9sZovNbKGZzTKzFkF7dTP72Mz2mNlTx2yTYGZj\nzexbM1tmZtdFsw8i+RETY9zc6UymP9iDPm3rMWbGSno99ikfLNms01dSakQtOMwsFhgFXA60APod\nDYYIE9y9tbu3Af4CHH2O+QHg18DPj7Pr/wdsdffmwX5nRKN+kdNRPTmRv95wHm8M7kxyYhz3vDyf\nu15MZ+32fWGXJnLaonnE0RFY4e4Z7n4ImAj0jlwheI75URUI7g1x973uPovcADnWncAfg/WOuPu2\naBQvUhg6pFTjvfu78fCV5zA3Yzu9/j6DJ6ct52C2Zt6VkiuawVEPWBfxeX3Q9gNmdp+ZrST3iOP+\nk+3QzKoEb39rZgvM7A0zO+ME6w4ys3QzS8/MzCxYD0QKQXxsDHdf0JiPHuxBz3POYMS/v+XykTOZ\ntVx/80jJFPrguLuPcvcmwEPAw6dYPQ6oD6S5ezvgM+BvJ9jvWHdPdffUmjX16BAJX53K5Rh1Szte\nGNCBHHdufW4uQycsYEvW8Q6sRYqvaAbHBqBBxOf6QduJTASuOcU+twP7gLeCz28A7QpaoEgYLjyr\nFh8M686wns34cOkWLhkxg/GzVpGdcyTs0kTyJJrBMQ9oZmaNzCwB6Evu42f/w8yaRXy8Elh+sh16\n7mUp7wIXBk2XAEsLq2CRopIUH8uwns35cFh32jWsyqPvLeWqp2Yzf82OsEsTOaUCP48jTzs3uwIY\nCcQC493992b2KJDu7lPM7HGgJ3AY2AEMdfclwbargUpAArATuNTdl5pZQ+BloAqQCQxw97Unq0PP\n45DizN3511ebeeTdpWzOOkDfDg146LKzqVohIezSpIw70fM4ohocxYWCQ0qCPQezeWLacp6btYpK\nSXEMv/xsbmjfgJgYPcFAwhGNBzmJSCFKTozjV1ecw/v3d6NprWQemryY68eksXRj1qk3FilCCg6R\nYubs2pWYdE9n/nr9uazevo+rnprFb99byp6DmrpEigcFh0gxZGbckNqA6Q/24KYODRg/exWXjPiE\n9xZt1NQlEjoFh0gxVqV8An/o05q3hnShRnIiQyd8Qf/xn5ORuSfs0qQMU3CIlABtz6zKlKHdeOTq\nlixcu5PLRs7ksQ+/4cBhTV0iRU/BIVJCxMYYt3dJYdrPe3BF69o8MX0Fvf4+g4+XbQ27NCljFBwi\nJUytikmM7NuWCQM7kRAbw4AX5nHPy+ls2Lk/7NKkjFBwiJRQXZrUYOpPu/M/l53FjG8z6TliBs/M\nWMlhTV0iUabgECnBEuJiuPfCpvz7Zz3o2rQGf5y6jCufmMncjO1hlyalmIJDpBRoUK08z96eyrj+\nqew9mMNNY+fwwKSFbNtzMOzSpBRScIiUIr1anMFHD/Tgvoua8O6XG7n4b5/w8pw15BzRvR9SeBQc\nIqVMuYRYfvFfZzP1p91pVa8yv37nK/o8PZtF63eGXZqUEgoOkVKqaa1kXr27E4/3bcOmXQfoPWo2\nv37nK3btPxx2aVLCKThESjEzo3ebekx7sAe3d07h1blruGTEJ7z9xXpNXSIFpuAQKQMqJcXzf1e3\nZMrQbtSrWp6fvf4lfcfOYfmW3WGXJiWQgkOkDGlVrzJvD+nCH/q0Ztnm3Vz++Ez+NHUZ+w5p5l3J\nOwWHSBkTE2Pc3OlMpj/Ygz5t6zFmxkp6PfYpHyzZrNNXkicKDpEyqnpyIn+94TzeGNyZ5MQ47nl5\nPne9mM7a7fvCLk2KOQWHSBnXIaUa793fjYevPIe5Gdvp9fcZPDltOQezNfOuHJ+CQ0SIj43h7gsa\n89GDPeh5zhmM+Pe3XD5yJrOWbwu7NCmGFBwi8h91Kpdj1C3tePHOjhxx59bn5jJ0wgK2ZB0IuzQp\nRhQcIvIjPZrX5F/DujOsZzM+XLqFS0bMYPysVWRr5l1BwSEiJ5AUH8uwns35cFh32jWsyqPvLeWq\np2Yzf82OsEuTkCk4ROSkUmpU4MUBHRh9Szt27D3EdaPTGD55ETv2Hgq7NAmJgkNETsnMuLx1HT56\nsAeDujfmjfnruXjEJ7w+by1HNPNumRPV4DCzy8zsGzNbYWbDj7N8sJktNrOFZjbLzFoE7dXN7GMz\n22NmT51g31PM7Kto1i8iP5ScGMevrjiH9+/vRtNayTw0eTHXj0lj6cassEuTIhS14DCzWGAUcDnQ\nAuh3NBgiTHD31u7eBvgL8FjQfgD4NfDzE+z7WmBPVAoXkVM6u3YlJt3Tmb/dcB6rt+/jqqdm8dCb\ni1ixVXNflQXRPOLoCKxw9wx3PwRMBHpHruDukX+mVAA8aN/r7rPIDZAfMLNk4AHgd9EqXEROzcy4\nvn19pj/Yg1s7nck7CzfQ87FPueuFeczJ2K7pS0qxaAZHPWBdxOf1QdsPmNl9ZraS3COO+/Ow398C\nI4CTzotgZoPMLN3M0jMzM/NetYjkS5XyCTzSuxVpwy9mWM9mfLFuJ33HzqH3qNm8++VGXcJbCoU+\nOO7uo9y9CfAQ8PDJ1jWzNkATd387D/sd6+6p7p5as2bNQqpWRE6kenIiw3o2J234xfy+Tyt2H8jm\nv1/7gh5//YTxs1ax96Bm4C0tohkcG4AGEZ/rB20nMhG45hT77AykmtlqYBbQ3Mw+OY0aRaSQJcXH\nckunhkx7oAdjb2tPncpJPPreUjr/cRp/+dcytuou9BIvmsExD2hmZo3MLAHoC0yJXMHMmkV8vBJY\nfrIduvtod6/r7ilAN+Bbd7+wUKsWkUIRE2Nc2rI2bw7pwuQhXejatAajZ6yk65+n84s3vuRbPUSq\nxIqL1o7dPdvMhgIfALHAeHdfYmaPAunuPgUYamY9gcPADuD2o9sHRxWVgAQzuwa41N2XRqteEYme\n9g2r0r5he9Zs38tzs1YxKUhfQ/wAAA2ySURBVH0db8xfz4Vn1WTQBY3p3KQ6ZhZ2mZJHVhaufEhN\nTfX09PSwyxCRwI69h3hlzhpe/Gw12/YcomXdSgzq3pgrWtchPjb0oVcJmNl8d0/9UbuCQ0TCcuBw\nDu98sYFxMzNYmbmXupWTuLNbI27q0ICKSfFhl1fmKTgUHCLF1pEjzsffbOWZTzP4fNV3VEyM4+ZO\nZzKgayNqV04Ku7wyS8Gh4BApERau28m4mRlMXbyJGDOublOXgRc05pw6lcIurcxRcCg4REqUdd/t\nY/zsVbw+bx37DuVwQbMaDOremG5Na2ggvYgoOBQcIiXSzn2HeHXuWl5IW03m7oOcXbsig7o35ifn\n1iUhTgPp0aTgUHCIlGgHs3P4x8KNjPs0g+Vb91C7UhIDuqbQr9OZVNJAelQoOBQcIqWCu/PJt5mM\n+zSDtJXbSU6Mo2+HBgzo1oh6VcqFXV6pouBQcIiUOl9t2MW4mRm8t2gTAD85tw4DL2hMq3qVQ66s\ndFBwKDhESq0NO/fz/KxVvPb5WvYeyqFLk+oM6t6YHs1raiD9NCg4FBwipd6u/Yd57fO1PD97FVuy\nDnLWGRW5+4JGXN2mLolxsWGXV+IoOBQcImXGoewjvPvlRsbNzGDZ5t3UqpjIHV1TuKVjQyqX10B6\nXik4FBwiZY67M3P5NsbNzGDm8m2UT4jlpg4NuLNrIxpUKx92ecWegkPBIVKmLd2YxbMzM5jy5UaO\nuHNF6zoM6t6Yc+tXCbu0YkvBoeAQEWDTrv28MHs1E+auZffBbM5vXI1B3RtzYfNaxMRoID2SgkPB\nISIRdh84zOvz1jF+1io27jpA01rJDLygEb3b1CMpXgPpoOBQcIjIcR3OOcL7izYx9tMMlm7KokZy\nInd0acgtnRpStUJC2OWFSsGh4BCRk3B30lZuZ+ynGcz4NpNy8bHcmFqfu7o15szqZXMgXcGh4BCR\nPFq2OYtnZ67iHws3kHPEuaxVbQZe0Ji2Z1YNu7QipeBQcIhIPm3JOsALaat5Zc4adh/IpmNKNQZ2\nb8wlZ5eNgXQFh4JDRApoz8FsJs1bx3OzVrFh534a16jA3Rc05tp2pXsgXcGh4BCR05Sdc4SpX21m\n7KcZLN6wi+oVEujfOYXbOjekWikcSFdwKDhEpJC4O3MyvmPczAymL9tKUnwM17fPHUhvVKNC2OUV\nmhMFR1wYxYiIlGRmRucm1encpDrLt+zm2ZmrmDRvPa/OXculLc5gUPfGtG9YLewyo0ZHHCIihWDr\n7gO8lLaGl+esYdf+w7Q7swqDujemV4vaxJbQgfQTHXFE9YG9ZnaZmX1jZivMbPhxlg82s8VmttDM\nZplZi6C9upl9bGZ7zOypiPXLm9n7ZrbMzJaY2Z+iWb+ISF7VqpjEz//rLD775cU8cnVLMvccZPAr\nC7hkxCe8PGcN+w/lhF1ioYnaEYeZxQLfAr2A9cA8oJ+7L41Yp5K7ZwXvrwbudffLzKwC0BZoBbRy\n96HBOuWBTu7+sZklANOAP7j71JPVoiMOESlqOUecD5Zs5plPM/hy3U6qlo/nts4p9O/ckBrJiWGX\nlydhjHF0BFa4e0ZQwESgN/Cf4DgaGoEKgAfte4FZZtY0cofuvg/4OHh/yMwWAPWj2AcRkQKJjTGu\naF2Hy1vVJn3NDp6ZkcET05YzZsZKrmtXn7svaESTmslhl1kg0QyOesC6iM/rgU7HrmRm9wEPAAnA\nxXnduZlVAa4CHj+9MkVEosfM6JBSjQ4p1ViZuYdnZ65i8oL1vPb5WnqekzuQ3iGlaol6xG1Uxzjy\nwt1HuXsT4CHg4bxsY2ZxwGvAE0ePaI6zziAzSzez9MzMzMIrWESkgJrUTOaP17YmbfjF3H9JM+av\n+Y4bn/mMa55O4/1Fm8jOORJ2iXkSzeDYADSI+Fw/aDuRicA1edz3WGC5u4880QruPtbdU909tWbN\nmnncrYhI9NVITuSBXs1JG34Jv72mFbv2HeK+CQu4aMQnvDB7FfsOZYdd4klFMzjmAc3MrFEwkN0X\nmBK5gpk1i/h4JbD8VDs1s98BlYFhhViriEiRK5cQy23nN2Tagxcy5tb21KqYxP+9u5TOf5zO3z74\nhq27D4Rd4nFF9T4OM7sCGAnEAuPd/fdm9iiQ7u5TzOxxoCdwGNgBDHX3JcG2q4FK5I597AQuBbLI\nHTdZBhwMfsxT7v7syerQVVUiUlLMX/Md4z5dxQdLNxMfE0OftvW4+4JGNDujYpHXoilHFBwiUoKs\n2raX8bNW8cb8dRw4fISLz67FwAsac37jakU2kK7gUHCISAn03d5DvDJnDS+mrWb73kO0rleZgd0b\nc0Wr2sTFRvf6JgWHgkNESrADh3N4a8EGnp2ZQca2vdSrUo47uzXipg4NSE6Mzp0VCg4Fh4iUAkeO\nONOWbWXcpxl8vvo7KibFcUunhgzomsIZlZIK9WcpOBQcIlLKfLF2B8/OXMXUrzYRG2P0blOPgRc0\n5qzahTOQruBQcIhIKbV2+z7Gz17F6/PWsf9wDj2a12RQ98Z0aVL9tAbSFRwKDhEp5XbuO8Src9fy\n/OzVbNtzkBZ1KvHCgA7UKuApLD3ISUSklKtSPoH7LmrKXd0aMWXhRj76ektUZuJVcIiIlDJJ8bHc\n2KEBN3ZocOqVCyD0SQ5FRKRkUXCIiEi+KDhERCRfFBwiIpIvCg4REckXBYeIiOSLgkNERPJFwSEi\nIvlSJqYcMbNMYE0BN68BbCvEcsJUWvpSWvoB6ktxVVr6crr9aOjuNY9tLBPBcTrMLP14c7WURKWl\nL6WlH6C+FFelpS/R6odOVYmISL4oOEREJF8UHKc2NuwCClFp6Utp6QeoL8VVaelLVPqhMQ4REckX\nHXGIiEi+KDhERCRfFBwBM7vMzL4xsxVmNvw4yxPN7PVg+VwzSyn6Kk8tD/24w8wyzWxh8Lo7jDrz\nwszGm9lWM/vqBMvNzJ4I+rrIzNoVdY15kYd+XGhmuyK+k/8t6hrzyswamNnHZrbUzJaY2U+Ps06x\n/17y2I8S8b2YWZKZfW5mXwZ9eeQ46xTu7y93L/MvIBZYCTQGEoAvgRbHrHMvMCZ43xd4Pey6C9iP\nO4Cnwq41j/3pDrQDvjrB8iuAqYAB5wNzw665gP24EHgv7Drz2Jc6QLvgfUXg2+P8Gyv230se+1Ei\nvpfgv3Ny8D4emAucf8w6hfr7S0ccuToCK9w9w90PAROB3ses0xt4MXj/JnCJmVkR1pgXeelHieHu\nnwLfnWSV3sBLnmsOUMXM6hRNdXmXh36UGO6+yd0XBO93A18D9Y5Zrdh/L3nsR4kQ/HfeE3yMD17H\nXvVUqL+/FBy56gHrIj6v58f/iP6zjrtnA7uA6kVSXd7lpR8A1wWnEN40s+g8lLho5LW/JUHn4FTD\nVDNrGXYxeRGc7mhL7l+4kUrU93KSfkAJ+V7MLNbMFgJbgX+7+wm/k8L4/aXgKHveBVLc/Vzg33z/\nV4iEZwG5cwKdBzwJvBNyPadkZsnAZGCYu2eFXU9BnaIfJeZ7cfccd28D1Ac6mlmraP48BUeuDUDk\nX971g7bjrmNmcUBlYHuRVJd3p+yHu29394PBx2eB9kVUWzTk5Xsr9tw96+ipBnf/JxBvZjVCLuuE\nzCye3F+2r7r7W8dZpUR8L6fqR0n7XgDcfSfwMXDZMYsK9feXgiPXPKCZmTUyswRyB4+mHLPOFOD2\n4P31wHQPRpqKkVP245hzzVeTe263pJoC9A+u4jkf2OXum8IuKr/MrPbR881m1pHc/18Wtz9KgNwr\npoDngK/d/bETrFbsv5e89KOkfC9mVtPMqgTvywG9gGXHrFaov7/iCrphaeLu2WY2FPiA3CuTxrv7\nEjN7FEh39ynk/iN72cxWkDvQ2Te8io8vj/2438yuBrLJ7ccdoRV8Cmb2GrlXttQws/XAb8gd+MPd\nxwD/JPcKnhXAPmBAOJWeXB76cT0wxMyygf1A32L4R8lRXYHbgMXBOXWAXwFnQon6XvLSj5LyvdQB\nXjSzWHLDbZK7vxfN31+ackRERPJFp6pERCRfFBwiIpIvCg4REckXBYeIiOSLgkNERPJFwSFSQGaW\nEzFz6kI7zmzEp7HvlBPNpisSNt3HIVJw+4NpHkTKFB1xiBQyM1ttZn8xs8XBcxKaBu0pZjY9mGBy\nmpmdGbSfYWZvB5PpfWlmXYJdxZrZuOAZCx8GdwVjZvcHz5FYZGYTQ+qmlGEKDpGCK3fMqaqbIpbt\ncvfWwFPAyKDtSeDFYILJV4EngvYngBnBZHrtgCVBezNglLu3BHYC1wXtw4G2wX4GR6tzIieiO8dF\nCsjM9rh78nHaVwMXu3tGMJHeZnevbmbbgDrufjho3+TuNcwsE6gfMfnk0am+/+3uzYLPDwHx7v47\nM/sXsIfc2VrfiXgWg0iR0BGHSHT4Cd7nx8GI9zl8PyZ5JTCK3KOTecFspyJFRsEhEh03RfzvZ8H7\nNL6fXO4WYGbwfhowBP7zQJ7KJ9qpmcUADdz9Y+AhcqfH/tFRj0g06S8VkYIrFzGzKsC/3P3oJblV\nzWwRuUcN/YK2/waeN7NfAJl8P2vsT4GxZnYXuUcWQ4ATTUMeC7wShIsBTwTPYBApMhrjEClkwRhH\nqrtvC7sWkWjQqSoREckXHXGIiEi+6IhDRETyRcEhIiL5ouAQEZF8UXCIiEi+KDhERCRf/j/9i3aC\ntAtt0gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "10000/10000 [==============================] - 1s 68us/step - loss: 0.3119\n",
            "Epoch 2/4\n",
            "10000/10000 [==============================] - 1s 71us/step - loss: 0.3119\n",
            "Epoch 3/4\n",
            "10000/10000 [==============================] - 1s 67us/step - loss: 0.3110\n",
            "Epoch 4/4\n",
            "10000/10000 [==============================] - 1s 64us/step - loss: 0.3107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMjApJxmpM3B",
        "colab_type": "text"
      },
      "source": [
        "# **AUTO ENCODER WITH GMM WITH NORMALIZED MUTUAL INFO SCORE** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqvuyVnR-mpV",
        "colab_type": "code",
        "outputId": "0391756c-a2ec-4b84-e112-e7b3c32f51a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install gmm_mml\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gmm_mml import GmmMml\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "print(\"Auto Encoder with GMM\")\n",
        "(x_train, y_train), (x_test,y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "#print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "x_train = x_train.astype('float32')/255.\n",
        "x_test = x_test.astype('float32')/255.\n",
        "\n",
        "x_train = x_train.reshape((len(x_train),np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test),np.prod(x_test.shape[1:])))\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "encoding_dim = 32\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "encoded = Dense(encoding_dim,activation='selu',kernel_regularizer=regularizers.l2(0.01))(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "autoencoder = Model(input_img,decoded)\n",
        "encoder = Model(input_img,encoded)\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train,x_train, epochs=20, batch_size=2056, shuffle=True, validation_data=(x_test,x_test))\n",
        "encoded_image = encoder.predict(x_test)\n",
        "\n",
        "clf = GmmMml()\n",
        "clf.fit(encoded_image)\n",
        "cm = confusion_matrix(y_test, clf.predict(encoded_image))\n",
        "print(\"CM\",cm)\n",
        "\n",
        "print('Accuracy: {}\\n'.format(metrics.normalized_mutual_info_score(y_test, clf.predict(encoded_image))))\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(classification_report(y_test,clf.predict(encoded_image)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gmm_mml in /usr/local/lib/python3.6/dist-packages (0.11)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from gmm_mml) (0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gmm_mml) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gmm_mml) (1.17.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->gmm_mml) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->gmm_mml) (0.14.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Auto Encoder with GMM\n",
            "(60000, 784)\n",
            "(10000, 784)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3492: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 1s 24us/step - loss: 1.0844 - val_loss: 0.8790\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.7516 - val_loss: 0.6452\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.6007 - val_loss: 0.5670\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5511 - val_loss: 0.5387\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5315 - val_loss: 0.5260\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5218 - val_loss: 0.5186\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5152 - val_loss: 0.5126\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5094 - val_loss: 0.5069\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.5036 - val_loss: 0.5010\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4977 - val_loss: 0.4951\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.4918 - val_loss: 0.4894\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4861 - val_loss: 0.4838\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4806 - val_loss: 0.4784\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4754 - val_loss: 0.4734\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4703 - val_loss: 0.4685\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4655 - val_loss: 0.4637\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 10us/step - loss: 0.4608 - val_loss: 0.4591\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4563 - val_loss: 0.4548\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4520 - val_loss: 0.4506\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 9us/step - loss: 0.4479 - val_loss: 0.4467\n",
            "CM [[ 26 822  82  59  11   0   0   0   0   0]\n",
            " [  1  55  16 926   2   0   0   0   0   0]\n",
            " [122  76 775   2  25   0   0   0   0   0]\n",
            " [ 13 382  19 584   2   0   0   0   0   0]\n",
            " [ 57 191 718  16  18   0   0   0   0   0]\n",
            " [402   1   0   0  51 546   0   0   0   0]\n",
            " [131 334 497  15  23   0   0   0   0   0]\n",
            " [  5   0   0   0  13 982   0   0   0   0]\n",
            " [110  69  67   0 741  13   0   0   0   0]\n",
            " [ 67   0   0   0 627 306   0   0   0   0]]\n",
            "Accuracy: 0.5152759141012774\n",
            "\n",
            "CLASSIFICATION REPORT\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.03      0.03      0.03      1000\n",
            "           1       0.03      0.06      0.04      1000\n",
            "           2       0.36      0.78      0.49      1000\n",
            "           3       0.36      0.58      0.45      1000\n",
            "           4       0.01      0.02      0.01      1000\n",
            "           5       0.30      0.55      0.38      1000\n",
            "           6       0.00      0.00      0.00      1000\n",
            "           7       0.00      0.00      0.00      1000\n",
            "           8       0.00      0.00      0.00      1000\n",
            "           9       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.20     10000\n",
            "   macro avg       0.11      0.20      0.14     10000\n",
            "weighted avg       0.11      0.20      0.14     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}