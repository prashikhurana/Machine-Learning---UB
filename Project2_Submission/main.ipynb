{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Lambda 1e-05\n",
      "\t Hidden Nodes:  10\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  3.260891474491085\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  3.2607599203898783\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  3.2603083200332392\n",
      "\t Accuracy for:  10 is:  10.27\n",
      "\t Hidden Nodes:  32\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  3.2607087719721677\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  3.260682118876588\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  3.2610247992879184\n",
      "\t Accuracy for:  32 is:  10.0\n",
      "\t Hidden Nodes:  64\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  3.260800680569092\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  3.260240057360763\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  3.260224253477195\n",
      "\t Accuracy for:  64 is:  10.0\n",
      "tp 0\n",
      "tn 0\n",
      "fp 0\n",
      "fn 0\n",
      "Final Accuracy for lambda  1e-05 is:  10.15\n",
      "For Lambda 0.001\n",
      "\t Hidden Nodes:  10\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  2.4536998454216046\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  1.110761393371417\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  0.9594128415435665\n",
      "\t Accuracy for:  10 is:  68.42\n",
      "\t Hidden Nodes:  32\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  2.2642518544781653\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  1.0061097455921795\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  0.8455335927801805\n",
      "\t Accuracy for:  32 is:  72.66\n",
      "\t Hidden Nodes:  64\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  2.6787003901127604\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  1.0411928391282583\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  0.8504804113175706\n",
      "\t Accuracy for:  64 is:  68.7\n",
      "tp 923\n",
      "tn 652\n",
      "fp 1\n",
      "fn 3\n",
      "Final Accuracy for lambda  0.001 is:  71.15\n",
      "For Lambda 0.01\n",
      "\t Hidden Nodes:  10\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  3.927484920470267\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  3.3047455625897326\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  3.314993379664136\n",
      "\t Accuracy for:  10 is:  10.0\n",
      "\t Hidden Nodes:  32\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  3.3142700690612585\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  3.3402675486693747\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  3.3251911514100465\n",
      "\t Accuracy for:  32 is:  10.01\n",
      "\t Hidden Nodes:  64\n",
      "\t\t Iteration 1\n",
      "\t\t Cost for Iteration  1 is:  3.333179929114795\n",
      "\t\t Iteration 5\n",
      "\t\t Cost for Iteration  5 is:  3.2849381916129885\n",
      "\t\t Iteration 7\n",
      "\t\t Cost for Iteration  7 is:  3.2701156003997736\n",
      "\t Accuracy for:  64 is:  10.0\n",
      "tp 0\n",
      "tn 0\n",
      "fp 0\n",
      "fn 0\n",
      "Final Accuracy for lambda  0.01 is:  10.65\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import util_mnist_reader\n",
    "import numpy as np\n",
    "from sklearn.utils.extmath import softmax\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = util_mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = util_mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "X_train = X_train/255\n",
    "y_train = y_train\n",
    "X_test = X_test/255\n",
    "y_test = y_test\n",
    "\n",
    "def find_first(item, vec,output_labels):\n",
    "    for i in range(output_labels-1):\n",
    "        if item == vec[i]:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x) *(1-sigmoid (x))\n",
    "\n",
    "def softmax(A):\n",
    "    expA = np.exp(A)\n",
    "    return expA / expA.sum(axis=1, keepdims=True)\n",
    "\n",
    "def convertOutput(y,output_labels):\n",
    "        #print(\"b\",np.shape(y))\n",
    "        y_c = np.zeros([y.shape[0],output_labels]) \n",
    "        y.reshape(y.shape[0],1)\n",
    "        for n in range(y.shape[0]):\n",
    "            b = y[n]    \n",
    "            y_c[n,b] = 1\n",
    "        return y_c\n",
    "\n",
    "def predictAcc(x,y,output_labels,wh,bh,wo,bo,t):\n",
    "        #print(\"ACC\")\n",
    "        m = np.size(x, 0)\n",
    "        o1 = sigmoid(np.dot(x, wh)+bh)\n",
    "        o2 = softmax(np.dot(o1, wo)+ bo)\n",
    "        b_c = np.zeros([o2.shape[0],1]) \n",
    "        for n in range(o2.shape[0]):\n",
    "            pred = o2[n,:]\n",
    "            i = 0\n",
    "            i = find_first(np.max(pred),pred,output_labels)\n",
    "            b_c[n,0] = i \n",
    "        o2= b_c\n",
    "        #print(\"o2\")\n",
    "        #print(o2)\n",
    "        acc = 0\n",
    "        c = 0\n",
    "        w = 0\n",
    "        tn =0\n",
    "        tp =0\n",
    "        fn =0\n",
    "        fp =0\n",
    "        for j in range(m):\n",
    "            if o2[j] == 1 and y[j] == 1:\n",
    "                tp=tp+1\n",
    "            elif o2[j] == 0 and y[j] == 0:\n",
    "                tn = tn+1\n",
    "            elif o2[j] == 0 and y[j] == 1:\n",
    "                fn = fn +1\n",
    "            elif o2[j] == 1 and y[j] == 0:\n",
    "                fp = fp +1\n",
    "        for n in range(m):\n",
    "            if y[n] == o2[n]:\n",
    "                c = c+1\n",
    "        acc = (c / (m))*100\n",
    "        if t==1:\n",
    "            print(\"tp\",tp)\n",
    "            print(\"tn\",tn)\n",
    "            print(\"fp\",fp)\n",
    "            print(\"fn\",fn)\n",
    "        #print(\"Y\", y)\n",
    "        #print(\"o2\", o2)\n",
    "        return acc\n",
    "    \n",
    "def convertZeroOne(c):\n",
    "    for n in range(np.size(c,0)):\n",
    "        if c[n] is 0:\n",
    "            c[n] = 0.000001\n",
    "        elif c[n] is 1:\n",
    "            c[n] = 0.999999\n",
    "    return c\n",
    "    \n",
    "def costFunction(y,a2,wh,wo,lamba):\n",
    "    \n",
    "    m = np.size(a2, 0)\n",
    "    B1 = np.log((a2))\n",
    "    B2 = np.log((1-a2))\n",
    "    B3 = y\n",
    "    B4 = 1-y\n",
    "        \n",
    "    T1 = (-1)*np.multiply(B3,B1)\n",
    "    T2 = (-1)*np.multiply(B2,B4)\n",
    "    R1 = np.add(T1,T2)\n",
    "    P1 = (sum(sum(R1 , 2))/m)\n",
    "        \n",
    "    wt1 = wh\n",
    "    T3 = np.square(wt1) \n",
    "    a = T3[0,0]\n",
    "    P2 = np.sum(T3)-a\n",
    "    wt2 = wo\n",
    "    T5 = np.square(wt2)\n",
    "    b = T5[0,0]\n",
    "    P3 = np.sum(T5)-b\n",
    "        \n",
    "    J = P1 + ((lamba/(2*m)) * (P2 + P3))\n",
    "    J = P1\n",
    "    return J\n",
    "        \n",
    "instances = X_train.shape[0]\n",
    "attributes = X_train.shape[1]\n",
    "hidden_nodesA = np.array([10,32,64])\n",
    "output_labels = 10\n",
    "\n",
    "\n",
    "lambaA = np.array([10e-6,10e-4,10e-3])\n",
    "lambaSet = np.size(lambaA)\n",
    "noItr = np.array([1,5,7])\n",
    "numitr = np.size(noItr)\n",
    "accuracyL = np.zeros([1,lambaSet])\n",
    "costI = np.zeros([lambaSet,numitr])\n",
    "                       \n",
    "for l in range(lambaSet):\n",
    "    \n",
    "    lr = lambaA[l]\n",
    "    print(\"For Lambda\",lr)\n",
    "    for kn in range(np.size(hidden_nodesA)):\n",
    "        print(\"\\t Hidden Nodes: \", hidden_nodesA[kn])\n",
    "        hidden_nodes = hidden_nodesA[kn]\n",
    "        wh = np.random.rand(attributes,hidden_nodes)/1000\n",
    "        bh = np.random.randn(hidden_nodes)/1000\n",
    "        wo = np.random.rand(hidden_nodes,output_labels)/1000\n",
    "        bo = np.random.randn(output_labels)/1000\n",
    "        maxacc = 0.00\n",
    "        maxwh = np.zeros([attributes,hidden_nodes])\n",
    "        maxwo = np.zeros([hidden_nodes,1])\n",
    "        maxbh = np.zeros([hidden_nodes,output_labels])\n",
    "        maxbo = np.zeros([output_labels,1])\n",
    "\n",
    "        for r in range(numitr):\n",
    "                numberOfIterations = noItr[r]\n",
    "                print('\\t\\t Iteration {}'.format(numberOfIterations))\n",
    "\n",
    "                for k in range(numberOfIterations):\n",
    "                    minibatch_size = 2000\n",
    "                    for j in range(0, X_train.shape[0], minibatch_size):\n",
    "                        #print(\"MINI BATCH SET: \\n\",j)\n",
    "                        \n",
    "                        X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "                        X_train_mini = X_train[j:j + minibatch_size]\n",
    "                        y_train_mini = y_train[j:j + minibatch_size]\n",
    "                        m = X_train_mini.shape[0]\n",
    "                        zh = np.dot(X_train_mini, wh) + bh\n",
    "                        ah = sigmoid(zh)\n",
    "                        zo = np.dot(ah, wo) + bo\n",
    "                        ao = softmax(zo)\n",
    "                        dcost_dzo = ao - convertOutput(y_train_mini,output_labels)\n",
    "                        dzo_dwo = ah\n",
    "                        dcost_wo = np.dot(dzo_dwo.T, dcost_dzo)\n",
    "                        dcost_bo = dcost_dzo\n",
    "                        dzo_dah = wo\n",
    "                        dcost_dah = np.dot(dcost_dzo , dzo_dah.T)\n",
    "                        dah_dzh = sigmoid_der(zh)\n",
    "                        dzh_dwh = X_train_mini\n",
    "                        dcost_wh = np.dot(dzh_dwh.T, dah_dzh * dcost_dah)\n",
    "                        dcost_bh = dcost_dah * dah_dzh\n",
    "                        wh -= lr * dcost_wh\n",
    "                        bh -= lr * (dcost_bh).sum(axis=0)\n",
    "                        wo -= lr * dcost_wo\n",
    "                        bo -= lr * (dcost_bo).sum(axis=0)\n",
    "                        if j % minibatch_size == 0:\n",
    "                            #print(\"\\t Minibatch Size:\", j / minibatch_size)\n",
    "                            loss = costFunction(convertOutput(y_train_mini,output_labels),ao,wh,wo,lr)\n",
    "                            #print('\\t\\t Loss function for Minibatch value: ', loss)\n",
    "                            acc = predictAcc(X_train_mini,y_train_mini,output_labels,wh,bh,wo,bo,0)\n",
    "                            #print(\"\\t\\t ACCURACY IS\",acc)\n",
    "\n",
    "                costI[l,r] = loss\n",
    "                print(\"\\t\\t Cost for Iteration \",numberOfIterations,\"is: \",costI[l,r])\n",
    "        print(\"\\t Accuracy for: \",hidden_nodes,\"is: \",predictAcc(X_test,y_test,output_labels,wh,bh,wo,bo,0))\n",
    "    accuracyL[0,l]=predictAcc(X_test,y_test,output_labels,wh,bh,wo,bo,1)\n",
    "    print(\"Final Accuracy for lambda \",lr,\"is: \",acc)\n",
    "\n",
    "lambaA= lambaA.reshape(lambaSet)\n",
    "accuracyL = accuracyL.reshape(lambaSet)\n",
    "plt.plot(lambaA,accuracyL)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "costf= costI[0,:]\n",
    "noItr = noItr.reshape(numitr)\n",
    "costf = costf.reshape(numitr)\n",
    "plt.plot(noItr, costf)\n",
    "plt.xlabel('No of Iterations')\n",
    "plt.ylabel('CostFunction')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import util_mnist_reader\n",
    "import numpy as np\n",
    "from sklearn.utils.extmath import softmax\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.callbacks import TensorBoard\n",
    "import os\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "x_train, y_train = util_mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "x_test, y_test = util_mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "print(\"Train Image Set Size: \",x_train.shape)\n",
    "print(\"Train Labels Set Size: \",y_train.shape)\n",
    "print(\"Test Image Set Size: \",x_test.shape)\n",
    "print(\"Test Labels Set Size: \",y_test.shape)\n",
    "\n",
    "model = models.Sequential()\n",
    "fc = layers.Dense(128, activation='sigmoid', input_dim=784)\n",
    "fc2 = layers.Dense(128 ,activation='relu')\n",
    "output = layers.Dense(10, 'softmax')\n",
    "model.add(fc)\n",
    "model.add(fc2)\n",
    "model.add(output)\n",
    "model.summary()\n",
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=30,\n",
    "         batch_size=128,\n",
    "         validation_data=(x_test,y_test),\n",
    "         )\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred.argmax(axis=1))\n",
    "print(\"Confusion matrix is\\n\", cm)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.15.0-rc3\n",
    "2.2.4-tf\n",
    "Train Image Set Size:  (60000, 784)\n",
    "Train Labels Set Size:  (60000,)\n",
    "Test Image Set Size:  (10000, 784)\n",
    "Test Labels Set Size:  (10000,)\n",
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_3 (Dense)              (None, 128)               100480    \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 128)               16512     \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 10)                1290      \n",
    "=================================================================\n",
    "Total params: 118,282\n",
    "Trainable params: 118,282\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Train on 60000 samples, validate on 10000 samples\n",
    "Epoch 1/30\n",
    "60000/60000 [==============================] - 2s 31us/sample - loss: 1.8867 - acc: 0.5260 - val_loss: 1.4579 - val_acc: 0.6492\n",
    "Epoch 2/30\n",
    "60000/60000 [==============================] - 2s 29us/sample - loss: 1.1952 - acc: 0.6862 - val_loss: 1.0241 - val_acc: 0.6947\n",
    "Epoch 3/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.9172 - acc: 0.7156 - val_loss: 0.8497 - val_acc: 0.7238\n",
    "Epoch 4/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.7890 - acc: 0.7353 - val_loss: 0.7570 - val_acc: 0.7356\n",
    "Epoch 5/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.7162 - acc: 0.7489 - val_loss: 0.7027 - val_acc: 0.7463\n",
    "Epoch 6/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.6709 - acc: 0.7590 - val_loss: 0.6656 - val_acc: 0.7577\n",
    "Epoch 7/30\n",
    "60000/60000 [==============================] - 2s 29us/sample - loss: 0.6389 - acc: 0.7682 - val_loss: 0.6397 - val_acc: 0.7671\n",
    "Epoch 8/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.6138 - acc: 0.7781 - val_loss: 0.6170 - val_acc: 0.7748\n",
    "Epoch 9/30\n",
    "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5927 - acc: 0.7854 - val_loss: 0.5985 - val_acc: 0.7828\n",
    "Epoch 10/30\n",
    "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5746 - acc: 0.7928 - val_loss: 0.5837 - val_acc: 0.7894\n",
    "Epoch 11/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5584 - acc: 0.8001 - val_loss: 0.5703 - val_acc: 0.7928\n",
    "Epoch 12/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5449 - acc: 0.8055 - val_loss: 0.5580 - val_acc: 0.8009\n",
    "Epoch 13/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5333 - acc: 0.8105 - val_loss: 0.5476 - val_acc: 0.8012\n",
    "Epoch 14/30\n",
    "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5225 - acc: 0.8148 - val_loss: 0.5393 - val_acc: 0.8043\n",
    "Epoch 15/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5134 - acc: 0.8177 - val_loss: 0.5304 - val_acc: 0.8075\n",
    "Epoch 16/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5052 - acc: 0.8209 - val_loss: 0.5241 - val_acc: 0.8113\n",
    "Epoch 17/30\n",
    "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4979 - acc: 0.8234 - val_loss: 0.5228 - val_acc: 0.8136\n",
    "Epoch 18/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4918 - acc: 0.8264 - val_loss: 0.5159 - val_acc: 0.8128\n",
    "Epoch 19/30\n",
    "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4861 - acc: 0.8273 - val_loss: 0.5102 - val_acc: 0.8155\n",
    "Epoch 20/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4806 - acc: 0.8301 - val_loss: 0.5036 - val_acc: 0.8186\n",
    "Epoch 21/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4756 - acc: 0.8317 - val_loss: 0.5006 - val_acc: 0.8215\n",
    "Epoch 22/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4713 - acc: 0.8344 - val_loss: 0.4974 - val_acc: 0.8215\n",
    "Epoch 23/30\n",
    "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4671 - acc: 0.8346 - val_loss: 0.4932 - val_acc: 0.8207\n",
    "Epoch 24/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4630 - acc: 0.8358 - val_loss: 0.4887 - val_acc: 0.8239\n",
    "Epoch 25/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4595 - acc: 0.8377 - val_loss: 0.4864 - val_acc: 0.8229\n",
    "Epoch 26/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4556 - acc: 0.8391 - val_loss: 0.4837 - val_acc: 0.8267\n",
    "Epoch 27/30\n",
    "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4526 - acc: 0.8400 - val_loss: 0.4810 - val_acc: 0.8265\n",
    "Epoch 28/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4493 - acc: 0.8410 - val_loss: 0.4787 - val_acc: 0.8280\n",
    "Epoch 29/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4463 - acc: 0.8421 - val_loss: 0.4755 - val_acc: 0.8289\n",
    "Epoch 30/30\n",
    "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4433 - acc: 0.8436 - val_loss: 0.4747 - val_acc: 0.8311\n",
    "10000/10000 [==============================] - 0s 28us/sample - loss: 0.4747 - acc: 0.8311\n",
    "Confusion matrix is\n",
    " [[812   2  19  55   5   4  88   0  15   0]\n",
    " [  2 946  11  31   6   0   2   0   2   0]\n",
    " [ 20   1 700   9 178   1  77   0  14   0]\n",
    " [ 30  13  12 851  43   1  45   0   5   0]\n",
    " [  0   0  84  30 807   0  74   0   5   0]\n",
    " [  0   0   0   1   0 908   0  56   3  32]\n",
    " [157   1 123  44 139   1 503   0  32   0]\n",
    " [  0   0   0   0   0  45   0 900   0  55]\n",
    " [  1   1   8  10   2   4  19   5 949   1]\n",
    " [  0   0   0   0   0  21   0  43   1 935]]\n",
    "0.8311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "#(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "train_images, train_labels = util_mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "test_images, test_labels = util_mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.astype('float32')/255\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "print(\"Train Image Set Size: \",train_images.shape)\n",
    "print(\"Train Labels Set Size: \",train_labels.shape)\n",
    "print(\"Test Image Set Size: \",test_images.shape)\n",
    "print(\"Test Labels Set Size: \",test_labels.shape)\n",
    "\n",
    "\n",
    "train_images = train_images.reshape((60000, 28,28, 1))\n",
    "test_images = test_images.reshape((10000, 28,28, 1))\n",
    "train_images_norm = train_images / 255.0\n",
    "test_images_norm = test_images / 255.0\n",
    "\n",
    "# First convolutional layer. \n",
    "# Number of neurons = 32\n",
    "# filter(kernel) size = 3x3\n",
    "# Activation function = Relu\n",
    "# input data (images) size (height, width, channels) = (28, 28, 1)\n",
    "# Channels is 'colors' here. Since fashion MNIST images are grayscale, number of colors = 1, hence, channels = 1\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1) )\n",
    "\n",
    "# Second convolutional layer. \n",
    "# Number of neurons = 64\n",
    "# filter(kernel) size = 3x3\n",
    "# Activation function = Relu\n",
    "# No separate input data for this layer, input to this layer are the 'weights' of the conv1 layer featureMaps\n",
    "# no need to specify explicitly the input to the other convolutional layers (except for the first layer, as above)\n",
    "\n",
    "conv2 = layers.Conv2D(64, (3,3), activation='relu')\n",
    "\n",
    "# Second convolutional layer. \n",
    "# Number of neurons = 128\n",
    "# filter(kernel) size = 3x3\n",
    "# Activation function = Relu\n",
    "# No separate input data for this layer, input to this layer are the 'weights' of the conv2 layer featureMaps\n",
    "# no need to specify explicitly the input to the other convolutional layers (except for the first layer, as above)\n",
    "\n",
    "conv3 = layers.Conv2D(128, (3,3), activation='relu')\n",
    "\n",
    "# Max Pool Layer\n",
    "# Since input to CNN is a 2-D image and ouput from last convolutional layer (featuerMap) is also 2-D array \n",
    "# (except the third dimension i.e. channels), we will use 2D version of Max Pooling function of TensorFlow Keras\n",
    "# to create a Max Pooling Layer, as shown below filter (kernel) size for Pooling Layer = 2x2\n",
    "\n",
    "#Creating first Max. Pooling Layer\n",
    "max_pool_1 = layers.MaxPooling2D((2,2))\n",
    "\n",
    "#Creating second Max. Pooling Layer\n",
    "max_pool_2 = layers.MaxPooling2D((2,2))\n",
    "\n",
    "#Creating third Max. Pooling Layer\n",
    "max_pool_3 = layers.MaxPooling2D((2,2))\n",
    "\n",
    "# Fully Connected (FC) Layer i.e. hidden layer expects input in 1-D format (1-D array), hence, we need to convert\n",
    "# 2-D output (2-D array) of last convolutional layer (conv3) to 1-D array i.e. we need to flatten the 2-D array\n",
    "# to 1-D array\n",
    "\n",
    "flat_layer = layers.Flatten()\n",
    "# Fully Connected (FC) Layer - Hidden(Dense) Layer\n",
    "# Normally, the number of neurons that we keep in FC layer should be equal to the number of neurons in just\n",
    "# immediate previous convolutional layer\n",
    "\n",
    "fc = layers.Dense(128, activation='relu')\n",
    "output = layers.Dense(10, 'softmax')\n",
    "modeln = models.Sequential()\n",
    "\n",
    "modeln.add(conv1)\n",
    "modeln.add(conv2)\n",
    "modeln.add(conv3)\n",
    "modeln.add(max_pool_1)\n",
    "modeln.add(flat_layer)\n",
    "modeln.add(fc)\n",
    "modeln.add(output)\n",
    "modeln.summary()\n",
    "modeln.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "modeln.fit(train_images_norm, train_labels, epochs=35, batch_size=512, shuffle=True, validation_split=0.1)\n",
    "\n",
    "test_loss, test_accuracy = modeln.evaluate(test_images_norm, test_labels)\n",
    "y_pred = modeln.predict(test_images)\n",
    "cm = confusion_matrix(test_labels, y_pred.argmax(axis=1))\n",
    "print(\"Confusion matrix is\\n\", cm)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.15.0-rc3\n",
    "2.2.4-tf\n",
    "Train Image Set Size:  (60000, 784)\n",
    "Train Labels Set Size:  (60000,)\n",
    "Test Image Set Size:  (10000, 784)\n",
    "Test Labels Set Size:  (10000,)\n",
    "Model: \"sequential_6\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_18 (Conv2D)           (None, 26, 26, 32)        320       \n",
    "_________________________________________________________________\n",
    "conv2d_19 (Conv2D)           (None, 24, 24, 64)        18496     \n",
    "_________________________________________________________________\n",
    "conv2d_20 (Conv2D)           (None, 22, 22, 128)       73856     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_18 (MaxPooling (None, 11, 11, 128)       0         \n",
    "_________________________________________________________________\n",
    "flatten_6 (Flatten)          (None, 15488)             0         \n",
    "_________________________________________________________________\n",
    "dense_12 (Dense)             (None, 128)               1982592   \n",
    "_________________________________________________________________\n",
    "dense_13 (Dense)             (None, 10)                1290      \n",
    "=================================================================\n",
    "Total params: 2,076,554\n",
    "Trainable params: 2,076,554\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Train on 54000 samples, validate on 6000 samples\n",
    "Epoch 1/35\n",
    "54000/54000 [==============================] - 11s 196us/sample - loss: 1.2076 - acc: 0.5651 - val_loss: 0.7184 - val_acc: 0.7190\n",
    "Epoch 2/35\n",
    "54000/54000 [==============================] - 10s 188us/sample - loss: 0.6433 - acc: 0.7590 - val_loss: 0.5951 - val_acc: 0.7630\n",
    "Epoch 3/35\n",
    "54000/54000 [==============================] - 10s 189us/sample - loss: 0.5744 - acc: 0.7870 - val_loss: 0.5467 - val_acc: 0.7933\n",
    "Epoch 4/35\n",
    "54000/54000 [==============================] - 10s 189us/sample - loss: 0.5329 - acc: 0.8030 - val_loss: 0.5156 - val_acc: 0.8043\n",
    "Epoch 5/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.5009 - acc: 0.8173 - val_loss: 0.4838 - val_acc: 0.8205\n",
    "Epoch 6/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.4799 - acc: 0.8239 - val_loss: 0.4777 - val_acc: 0.8208\n",
    "Epoch 7/35\n",
    "54000/54000 [==============================] - 10s 191us/sample - loss: 0.4582 - acc: 0.8335 - val_loss: 0.4560 - val_acc: 0.8283\n",
    "Epoch 8/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.4444 - acc: 0.8383 - val_loss: 0.4748 - val_acc: 0.8213\n",
    "Epoch 9/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.4341 - acc: 0.8423 - val_loss: 0.4304 - val_acc: 0.8407\n",
    "Epoch 10/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.4171 - acc: 0.8495 - val_loss: 0.4160 - val_acc: 0.8470\n",
    "Epoch 11/35\n",
    "54000/54000 [==============================] - 10s 191us/sample - loss: 0.3991 - acc: 0.8559 - val_loss: 0.4096 - val_acc: 0.8495\n",
    "Epoch 12/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.3865 - acc: 0.8607 - val_loss: 0.4066 - val_acc: 0.8472\n",
    "Epoch 13/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.3738 - acc: 0.8644 - val_loss: 0.3808 - val_acc: 0.8560\n",
    "Epoch 14/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.3618 - acc: 0.8697 - val_loss: 0.3745 - val_acc: 0.8605\n",
    "Epoch 15/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.3450 - acc: 0.8750 - val_loss: 0.3696 - val_acc: 0.8645\n",
    "Epoch 16/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.3362 - acc: 0.8780 - val_loss: 0.3444 - val_acc: 0.8737\n",
    "Epoch 17/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.3242 - acc: 0.8820 - val_loss: 0.3381 - val_acc: 0.8768\n",
    "Epoch 18/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.3133 - acc: 0.8859 - val_loss: 0.3368 - val_acc: 0.8788\n",
    "Epoch 19/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.3056 - acc: 0.8896 - val_loss: 0.3117 - val_acc: 0.8848\n",
    "Epoch 20/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2993 - acc: 0.8906 - val_loss: 0.3107 - val_acc: 0.8877\n",
    "Epoch 21/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2901 - acc: 0.8943 - val_loss: 0.3065 - val_acc: 0.8890\n",
    "Epoch 22/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2818 - acc: 0.8971 - val_loss: 0.3067 - val_acc: 0.8887\n",
    "Epoch 23/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2726 - acc: 0.9008 - val_loss: 0.3061 - val_acc: 0.8860\n",
    "Epoch 24/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2654 - acc: 0.9027 - val_loss: 0.3087 - val_acc: 0.8895\n",
    "Epoch 25/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2612 - acc: 0.9039 - val_loss: 0.3048 - val_acc: 0.8892\n",
    "Epoch 26/35\n",
    "54000/54000 [==============================] - 10s 189us/sample - loss: 0.2527 - acc: 0.9080 - val_loss: 0.2928 - val_acc: 0.8977\n",
    "Epoch 27/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2429 - acc: 0.9114 - val_loss: 0.2867 - val_acc: 0.8973\n",
    "Epoch 28/35\n",
    "54000/54000 [==============================] - 10s 189us/sample - loss: 0.2351 - acc: 0.9141 - val_loss: 0.2805 - val_acc: 0.8972\n",
    "Epoch 29/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2332 - acc: 0.9152 - val_loss: 0.2940 - val_acc: 0.8897\n",
    "Epoch 30/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2263 - acc: 0.9176 - val_loss: 0.2732 - val_acc: 0.8997\n",
    "Epoch 31/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2202 - acc: 0.9190 - val_loss: 0.2729 - val_acc: 0.9022\n",
    "Epoch 32/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2158 - acc: 0.9214 - val_loss: 0.2697 - val_acc: 0.9030\n",
    "Epoch 33/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.2094 - acc: 0.9224 - val_loss: 0.2889 - val_acc: 0.8985\n",
    "Epoch 34/35\n",
    "54000/54000 [==============================] - 10s 189us/sample - loss: 0.2050 - acc: 0.9245 - val_loss: 0.2851 - val_acc: 0.9025\n",
    "Epoch 35/35\n",
    "54000/54000 [==============================] - 10s 190us/sample - loss: 0.1970 - acc: 0.9272 - val_loss: 0.2709 - val_acc: 0.9035\n",
    "10000/10000 [==============================] - 1s 140us/sample - loss: 0.2867 - acc: 0.9026\n",
    "Confusion matrix is\n",
    " [[470   7 200  17  71   0 194   0  41   0]\n",
    " [  1 920   1  20  10   0  29   0  18   1]\n",
    " [ 18   0 625   6 208   1 136   0   6   0]\n",
    " [  4  23  19 627  97   0 120   0 103   7]\n",
    " [  2   2  40  20 847   0  78   0   9   2]\n",
    " [ 91   3   0   0   0 848  12   0  44   2]\n",
    " [ 59   4  51  14 312   1 542   0  17   0]\n",
    " [  4   0   0   0   0 279  48 467 137  65]\n",
    " [ 32   3  16   3   4   2  46   0 893   1]\n",
    " [106   5   0   0   0  16 425   9  93 346]]\n",
    "0.9026\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
